@inproceedings{pytorch,
author = {Ansel, Jason and Yang, Edward and He, Horace and Gimelshein, Natalia and Jain, Animesh and Voznesensky, Michael and Bao, Bin and Bell, Peter and Berard, David and Burovski, Evgeni and Chauhan, Geeta and Chourdia, Anjali and Constable, Will and Desmaison, Alban and DeVito, Zachary and Ellison, Elias and Feng, Will and Gong, Jiong and Gschwind, Michael and Hirsh, Brian and Huang, Sherlock and Kalambarkar, Kshiteej and Kirsch, Laurent and Lazos, Michael and Lezcano, Mario and Liang, Yanbo and Liang, Jason and Lu, Yinghai and Luk, CK and Maher, Bert and Pan, Yunjie and Puhrsch, Christian and Reso, Matthias and Saroufim, Mark and Siraichi, Marcos Yukio and Suk, Helen and Suo, Michael and Tillet, Phil and Wang, Eikan and Wang, Xiaodong and Wen, William and Zhang, Shunting and Zhao, Xu and Zhou, Keren and Zou, Richard and Mathews, Ajit and Chanan, Gregory and Wu, Peng and Chintala, Soumith},
booktitle = {29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2 (ASPLOS '24)},
doi = {10.1145/3620665.3640366},
publisher = {ACM},
title = {{PyTorch 2: Faster Machine Learning Through Dynamic Python Bytecode Transformation and Graph Compilation}},
url = {https://pytorch.org/assets/pytorch2-2.pdf},
year = {2024}
}

@inproceedings{cohen2016,
  title = {Group {{Equivariant Convolutional Networks}}},
  booktitle = {Proceedings of {{The}} 33rd {{International Conference}} on {{Machine Learning}}},
  author = {Cohen, Taco and Welling, Max},
  editor = {Balcan, Maria Florina and Weinberger, Kilian Q},
  date = {2016-03},
  volume = {48},
  pages = {2990--2999},
  publisher = {PMLR},
  location = {New York, New York, USA},
  url = {https://proceedings.mlr.press/v48/cohenc16.html},
  abstract = {We introduce Group equivariant Convolutional Neural Networks (G-CNNs), a natural generalization of convolutional neural networks that reduces sample complexity by exploiting symmetries. G-CNNs use G-convolutions, a new type of layer that enjoys a substantially higher degree of weight sharing than regular convolution layers. G-convolutions increase the expressive capacity of the network without increasing the number of parameters. Group convolution layers are easy to use and can be implemented with negligible computational overhead for discrete groups generated by translations, reflections and rotations. G-CNNs achieve state of the art results on CIFAR10 and rotated MNIST.}
}

@online{escnn1,
  title = {General \${{E}}(2)\$-{{Equivariant Steerable CNNs}}},
  author = {Weiler, Maurice and Cesa, Gabriele},
  date = {2021-04-06},
  eprint = {1911.08251},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.1911.08251},
  url = {http://arxiv.org/abs/1911.08251},
  urldate = {2024-11-15},
  abstract = {The big empirical success of group equivariant networks has led in recent years to the sprouting of a great variety of equivariant network architectures. A particular focus has thereby been on rotation and reflection equivariant CNNs for planar images. Here we give a general description of \$E(2)\$-equivariant convolutions in the framework of Steerable CNNs. The theory of Steerable CNNs thereby yields constraints on the convolution kernels which depend on group representations describing the transformation laws of feature spaces. We show that these constraints for arbitrary group representations can be reduced to constraints under irreducible representations. A general solution of the kernel space constraint is given for arbitrary representations of the Euclidean group \$E(2)\$ and its subgroups. We implement a wide range of previously proposed and entirely new equivariant network architectures and extensively compare their performances. \$E(2)\$-steerable convolutions are further shown to yield remarkable gains on CIFAR-10, CIFAR-100 and STL-10 when used as a drop-in replacement for non-equivariant convolutions.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image and Video Processing}
}

@inproceedings{escnn2,
  title = {A {{Program}} to {{Build E}}({{N}})-{{Equivariant Steerable CNNs}}},
  author = {Cesa, Gabriele and Lang, Leon and Weiler, Maurice},
  date = {2021-10-06},
  url = {https://openreview.net/forum?id=WE4qe9xlnQw},
  urldate = {2024-11-15},
  abstract = {Equivariance is becoming an increasingly popular design choice to build data efficient neural networks by exploiting prior knowledge about the symmetries of the problem at hand. Euclidean steerable CNNs are one of the most common classes of equivariant networks. While the constraints these architectures need to satisfy are understood, existing approaches are tailored to specific (classes of) groups. No generally applicable method that is practical for implementation has been described so far. In this work, we generalize the Wigner-Eckart theorem proposed in Lang \& Weiler (2020), which characterizes general \$G\$-steerable kernel spaces for compact groups \$G\$ over their homogeneous spaces, to arbitrary \$G\$-spaces. This enables us to directly parameterize filters in terms of a band-limited basis on the whole space rather than on \$G\$'s orbits, but also to easily implement steerable CNNs equivariant to a large number of groups. To demonstrate its generality, we instantiate our method on a variety of isometry groups acting on the Euclidean space \$\textbackslash mathbb\{R\}\textasciicircum 3\$. Our framework allows us to build \$E(3)\$ and \$SE(3)\$-steerable CNNs like previous works, but also CNNs with arbitrary \$G\textbackslash leq O(3)\$-steerable kernels. For example, we build 3D CNNs equivariant to the symmetries of platonic solids or choose \$G=SO(2)\$ when working with 3D data having only azimuthal symmetries. We compare these models on 3D shapes and molecular datasets, observing improved performance by matching the model's symmetries to the ones of the data.},
  eventtitle = {International {{Conference}} on {{Learning Representations}}},
  langid = {english}
}

@software{torchvision,
author = {{TorchVision maintainers and contributors}},
license = {BSD-3-Clause},
month = nov,
title = {{TorchVision: PyTorch's Computer Vision library}},
url = {https://github.com/pytorch/vision},
year = {2016}
}

@misc{resnet,
      title={Deep Residual Learning for Image Recognition},
      author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
      year={2015},
      eprint={1512.03385},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1512.03385},
      doi = {10.48550/arXiv.1512.03385}
}

 @InProceedings{9506614,
 author={Yasarla, Rajeev and Patel, Vishal M.},
 booktitle={2021 IEEE International Conference on Image Processing (ICIP)},
 title={Learning to Restore Images Degraded by Atmospheric Turbulence Using Uncertainty},
 year={2021},
 pages={1694-1698},
 doi={10.1109/ICIP42928.2021.9506614}
 }

 @InProceedings{zhang2024spatio,
    author={Zhang, Xingguang and Chimitt, Nicholas and Chi, Yiheng and Mao, Zhiyuan and Chan, Stanley H},
    title={Spatio-Temporal Turbulence Mitigation: A Translational Perspective},
    booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month={June},
    year={2024}
}
